{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "q1rNHXSVtFjd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "with open(\"themes.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    THEMES = json.load(f)\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "maze_size = (20, 20)\n",
    "participant_id = 23634 ## SR.No\n",
    "enable_enemy = False\n",
    "enable_trap_boost = False\n",
    "save_path = f\"{participant_id}.pkl\"\n",
    "\n",
    "# Q-learning parameters\n",
    "###################################\n",
    "#      WRITE YOUR CODE BELOW      #\n",
    "num_actions = 4\n",
    "gamma = 0.9               # between 0 - 1\n",
    "alpha = 0.7               # between 0 - 1\n",
    "epsilon = 0.7             # between 0 - 1\n",
    "epsilon_decay = 0.999      # between 0.1 - 1\n",
    "min_epsilon = 0.1\n",
    "num_episodes = 10000   \n",
    "max_steps = 2000 \n",
    "###################################     \n",
    "\n",
    "actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Up, Down, Left, Right\n",
    "\n",
    "# ========== REWARDS ==========\n",
    "###################################\n",
    "#      WRITE YOUR CODE BELOW      #\n",
    "REWARD_GOAL     = 10   # Reward for reaching goal.\n",
    "REWARD_TRAP     = -500     # Trap cell.\n",
    "REWARD_OBSTACLE = -10    # Obstacle cell.\n",
    "REWARD_REVISIT  = -100    # Revisiting same cell.\n",
    "REWARD_ENEMY    = -10    # Getting caught by enemy.\n",
    "REWARD_STEP     = -10   # Per-step time penalty.\n",
    "REWARD_BOOST    = 1      # Boost cell.\n",
    "###################################\n",
    "# =============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "FKJ5KM_rtJ3q"
   },
   "outputs": [],
   "source": [
    "# Environment\n",
    "class MazeGymEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, maze_size, participant_id, enable_enemy, enable_trap_boost, max_steps):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        initialize the maze_size, participant_id, enable_enemy, enable_trap_boost and max_steps variables\n",
    "        \"\"\"\n",
    "        ###################################\n",
    "        #      WRITE YOUR CODE BELOW      #\n",
    "        self.maze_size = maze_size\n",
    "        self.participant_id = participant_id\n",
    "        self.enable_enemy = enable_enemy\n",
    "        self.enable_trap_boost = enable_trap_boost\n",
    "        self.max_steps = max_steps\n",
    "        ###################################\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(maze_size[0]),\n",
    "            spaces.Discrete(maze_size[1])\n",
    "        ))\n",
    "\n",
    "        \"\"\"\n",
    "        generate  self.maze using the _generate_obstacles method\n",
    "        make self.start as the top left cell of the maze and self.goal as the bottom right\n",
    "        \"\"\"\n",
    "        ###################################\n",
    "        #      WRITE YOUR CODE BELOW      #\n",
    "        self.maze = self._generate_obstacles()\n",
    "        self.start = (0, 0)\n",
    "        self.goal = (self.maze_size[0]-1, self.maze_size[1]-1)\n",
    "        ###################################\n",
    "\n",
    "        if self.enable_trap_boost:\n",
    "            self.trap_cells, self.boost_cells = self._generate_traps_and_boosts(self.maze)\n",
    "        else:\n",
    "            self.trap_cells, self.boost_cells = ([], [])\n",
    "\n",
    "        self.enemy_cells = []\n",
    "        self.current_step = 0\n",
    "        self.agent_pos = None\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        \"\"\"\n",
    "        generates the maze with random obstacles based on the SR.No.\n",
    "        \"\"\"\n",
    "        np.random.seed(self.participant_id)\n",
    "        maze = np.zeros(self.maze_size, dtype=int)\n",
    "        mask = np.ones(self.maze_size, dtype=bool)\n",
    "        safe_cells = [\n",
    "            (0, 0), (0, 1), (1, 0),\n",
    "            (self.maze_size[0]-1, self.maze_size[1]-1), (self.maze_size[0]-2, self.maze_size[1]-1),\n",
    "            (self.maze_size[0]-1, self.maze_size[1]-2)\n",
    "        ]\n",
    "        for row, col in safe_cells:\n",
    "            mask[row, col] = False\n",
    "        maze[mask] = np.random.choice([0, 1], size=mask.sum(), p=[0.9, 0.1])\n",
    "        return maze\n",
    "\n",
    "    def _generate_traps_and_boosts(self, maze):\n",
    "        \"\"\"\n",
    "        generates special cells, traps and boosts. While training our agent,\n",
    "        we want to pass thru more number of boost cells and avoid trap cells \n",
    "        \"\"\"\n",
    "        if not self.enable_trap_boost:\n",
    "            return [], []\n",
    "        exclusions = {self.start, self.goal}\n",
    "        empty_cells = list(zip(*np.where(maze == 0)))\n",
    "        valid_cells = [cell for cell in empty_cells if cell not in exclusions]\n",
    "        num_traps = self.maze_size[0] * 2\n",
    "        num_boosts = self.maze_size[0] * 2\n",
    "        random.seed(self.participant_id)\n",
    "        trap_cells = random.sample(valid_cells, num_traps)\n",
    "        trap_cells_ = trap_cells\n",
    "        remaining_cells = [cell for cell in valid_cells if cell not in trap_cells]\n",
    "        boost_cells = random.sample(remaining_cells, num_boosts)\n",
    "        boost_cells_ = boost_cells\n",
    "        return trap_cells, boost_cells\n",
    "\n",
    "    def move_enemy(self, enemy_pos):\n",
    "        possible_moves = []\n",
    "        for dx, dy in actions:\n",
    "            new_pos = (enemy_pos[0] + dx, enemy_pos[1] + dy)\n",
    "            if (0 <= new_pos[0] < self.maze_size[0] and\n",
    "                0 <= new_pos[1] < self.maze_size[1] and\n",
    "                self.maze[new_pos] != 1):\n",
    "                possible_moves.append(new_pos)\n",
    "        return random.choice(possible_moves) if possible_moves else enemy_pos\n",
    "\n",
    "    def update_enemies(self):\n",
    "        if self.enable_enemy:\n",
    "            self.enemy_cells = [self.move_enemy(enemy) for enemy in self.enemy_cells]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        empty_cells = list(zip(*np.where(self.maze == 0)))\n",
    "        self.start = (0, 0)\n",
    "        self.goal = (self.maze_size[0]-1, self.maze_size[1]-1)\n",
    "\n",
    "        for pos in (self.start, self.goal):\n",
    "            if pos in self.trap_cells:\n",
    "                self.trap_cells.remove(pos)\n",
    "            if pos in self.boost_cells:\n",
    "                self.boost_cells.remove(pos)\n",
    "\n",
    "        if self.enable_enemy:\n",
    "            enemy_candidates = [cell for cell in empty_cells if cell not in {self.start, self.goal}]\n",
    "            num_enemies = max(1, int((self.maze_size[0] * self.maze_size[1]) / 100))\n",
    "            self.enemy_cells = random.sample(enemy_candidates, min(num_enemies, len(enemy_candidates)))\n",
    "        else:\n",
    "            self.enemy_cells = []\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.agent_pos = self.start\n",
    "        self.visited = set()\n",
    "\n",
    "\n",
    "        return self.agent_pos, {}\n",
    "\n",
    "    def get_reward(self, state):\n",
    "        if state == self.goal:\n",
    "            return REWARD_GOAL\n",
    "        elif state in self.trap_cells:\n",
    "            return REWARD_TRAP\n",
    "        elif state in self.boost_cells:\n",
    "            return REWARD_BOOST\n",
    "        elif self.maze[state] == 1:\n",
    "            return REWARD_OBSTACLE\n",
    "        else:\n",
    "            return REWARD_STEP\n",
    "\n",
    "    def take_action(self, state, action):\n",
    "        attempted_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "        if (0 <= attempted_state[0] < self.maze_size[0] and\n",
    "            0 <= attempted_state[1] < self.maze_size[1] and\n",
    "            self.maze[attempted_state] != 1):\n",
    "            return attempted_state, False\n",
    "        else:\n",
    "            return state, True\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        next_state, wall_collision = self.take_action(self.agent_pos, action)\n",
    "        if wall_collision:\n",
    "            reward = REWARD_OBSTACLE\n",
    "            next_state = self.agent_pos\n",
    "        else:\n",
    "            if self.enable_enemy:\n",
    "                self.update_enemies()\n",
    "            if self.enable_enemy and next_state in self.enemy_cells:\n",
    "                reward = REWARD_ENEMY\n",
    "                done = True\n",
    "                truncated = True\n",
    "                info = {'terminated_by': 'enemy'}\n",
    "                self.agent_pos = next_state\n",
    "                return self.agent_pos, reward, done, truncated, info\n",
    "            else:\n",
    "                revisit_penalty = REWARD_REVISIT if next_state in self.visited else 0\n",
    "                self.visited.add(next_state)\n",
    "                reward = self.get_reward(next_state) + revisit_penalty\n",
    "        self.agent_pos = next_state\n",
    "\n",
    "        if self.agent_pos == self.goal:\n",
    "            done = True\n",
    "            truncated = False\n",
    "            info = {'completed_by': 'goal'}\n",
    "        elif self.current_step >= self.max_steps:\n",
    "            done = True\n",
    "            truncated = True\n",
    "            info = {'terminated_by': 'timeout'}\n",
    "        else:\n",
    "            done = False\n",
    "            truncated = False\n",
    "            info = {\n",
    "                'current_step': self.current_step,\n",
    "                'agent_position': self.agent_pos,\n",
    "                'remaining_steps': self.max_steps - self.current_step\n",
    "            }\n",
    "\n",
    "        return self.agent_pos, reward, done, truncated, info\n",
    "\n",
    "    def render(self, path=None, theme=\"racing\"):\n",
    "        icons = THEMES.get(theme, THEMES[\"racing\"])\n",
    "        clear_output(wait=True)\n",
    "        grid = np.full(self.maze_size, icons[\"empty\"])\n",
    "        grid[self.maze == 1] = icons[\"obstacle\"]\n",
    "        for cell in self.trap_cells:\n",
    "            grid[cell] = icons[\"trap\"]\n",
    "        for cell in self.boost_cells:\n",
    "            grid[cell] = icons[\"boost\"]\n",
    "        grid[self.start] = icons[\"start\"]\n",
    "        grid[self.goal] = icons[\"goal\"]\n",
    "        if path is not None:\n",
    "            for cell in path[1:-1]:\n",
    "                if grid[cell] not in (icons[\"goal\"], icons[\"obstacle\"], icons[\"trap\"], icons[\"boost\"]):\n",
    "                    grid[cell] = icons[\"path\"]\n",
    "        if self.agent_pos is not None:\n",
    "            if grid[self.agent_pos] not in (icons[\"goal\"], icons[\"obstacle\"]):\n",
    "                grid[self.agent_pos] = icons[\"agent\"]\n",
    "        if self.enable_enemy:\n",
    "            for enemy in self.enemy_cells:\n",
    "                grid[enemy] = icons[\"enemy\"]\n",
    "        df = pd.DataFrame(grid)\n",
    "        print(df.to_string(index=False, header=False))\n",
    "\n",
    "    def print_final_message(self, success, interrupted, caught, theme):\n",
    "        msgs = THEMES.get(theme, THEMES[\"racing\"]).get(\"final_messages\", {})\n",
    "        if interrupted:\n",
    "            print(f\"\\n{msgs.get('Interrupted', '🛑 Interrupted.')}\")\n",
    "        elif caught:\n",
    "            print(f\"\\n{msgs.get('Defeat', '🚓 Caught by enemy.')}\")\n",
    "        elif success:\n",
    "            print(f\"\\n{msgs.get('Triumph', '🏁 Success.')}\")\n",
    "        else:\n",
    "            print(f\"\\n{msgs.get('TimeOut', '⛽ Time Out.')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "-En22A4ftMdT"
   },
   "outputs": [],
   "source": [
    "# Agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, maze_size, num_actions, alpha=0.1, gamma=0.99):\n",
    "        \"\"\"\n",
    "        initialize self.num_actions, self.alpha, self.gamma\n",
    "        initialize self.q_table based on number of states and number of actions\n",
    "        \"\"\"\n",
    "        ###################################\n",
    "        #      WRITE YOUR CODE BELOW      #\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_table = np.zeros((maze_size[0], maze_size[1], num_actions))\n",
    "        ###################################\n",
    "        \n",
    "\n",
    "    def choose_action(self, env, state, epsilon):\n",
    "        \"\"\"\n",
    "        returns an integer between [0,3]\n",
    "\n",
    "        epsilon is a parameter between 0 and 1.\n",
    "        It is the probability with which we choose an exploratory action (random action)\n",
    "        Eg: ---\n",
    "        If epsilon = 0.25, probability of choosing action from q_table = 0.75\n",
    "                           probability of choosing random action = 0.25\n",
    "        \"\"\"\n",
    "        ###################################\n",
    "        #      WRITE YOUR CODE BELOW      #\n",
    "        if np.random.rand() < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "        ###################################\n",
    "\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Use the Q-learning update equation to update the Q-Table\n",
    "        \"\"\"\n",
    "        ###################################\n",
    "        #      WRITE YOUR CODE BELOW      #\n",
    "        self.q_table[state][action] = self.q_table[state][action] + self.alpha * (reward + self.gamma * np.max(self.q_table[next_state]) - self.q_table[state][action])\n",
    "        ###################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ebdQy-8tPw-",
    "outputId": "ac14a863-71c6-47af-f00e-842c43502cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best at episode 0: 1336 steps and Reward -209140.00\n",
      "Episode 0/10000 - Epsilon: 0.9990 - Total Steps: 1336 - Episode Reward: -209140.00 - Best Reward: -209140.00\n",
      "New best at episode 2: 811 steps and Reward -117190.00\n",
      "New best at episode 9: 544 steps and Reward -79220.00\n",
      "New best at episode 30: 355 steps and Reward -47830.00\n",
      "New best at episode 41: 346 steps and Reward -45040.00\n",
      "New best at episode 79: 189 steps and Reward -19970.00\n",
      "New best at episode 83: 123 steps and Reward -11310.00\n",
      "New best at episode 110: 118 steps and Reward -10760.00\n",
      "New best at episode 209: 100 steps and Reward -8580.00\n",
      "New best at episode 214: 102 steps and Reward -8000.00\n",
      "New best at episode 228: 83 steps and Reward -5810.00\n",
      "New best at episode 362: 72 steps and Reward -4400.00\n",
      "New best at episode 491: 57 steps and Reward -2850.00\n",
      "New best at episode 539: 54 steps and Reward -2120.00\n",
      "New best at episode 704: 48 steps and Reward -1660.00\n",
      "New best at episode 747: 42 steps and Reward -800.00\n",
      "Episode 1000/10000 - Epsilon: 0.3673 - Total Steps: 67 - Episode Reward: -4150.00 - Best Reward: -800.00\n",
      "New best at episode 1195: 43 steps and Reward -710.00\n",
      "New best at episode 1340: 39 steps and Reward -470.00\n",
      "New best at episode 1511: 38 steps and Reward -360.00\n",
      "Episode 2000/10000 - Epsilon: 0.1351 - Total Steps: 47 - Episode Reward: -1150.00 - Best Reward: -360.00\n",
      "Episode 3000/10000 - Epsilon: 0.1000 - Total Steps: 42 - Episode Reward: -1000.00 - Best Reward: -360.00\n",
      "Episode 4000/10000 - Epsilon: 0.1000 - Total Steps: 46 - Episode Reward: -1440.00 - Best Reward: -360.00\n",
      "Episode 5000/10000 - Epsilon: 0.1000 - Total Steps: 41 - Episode Reward: -690.00 - Best Reward: -360.00\n",
      "Episode 6000/10000 - Epsilon: 0.1000 - Total Steps: 46 - Episode Reward: -1640.00 - Best Reward: -360.00\n",
      "Episode 7000/10000 - Epsilon: 0.1000 - Total Steps: 48 - Episode Reward: -1860.00 - Best Reward: -360.00\n",
      "Episode 8000/10000 - Epsilon: 0.1000 - Total Steps: 40 - Episode Reward: -780.00 - Best Reward: -360.00\n",
      "Episode 9000/10000 - Epsilon: 0.1000 - Total Steps: 45 - Episode Reward: -1130.00 - Best Reward: -360.00\n",
      "\n",
      "Training completed. Total episodes: 9999\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "env = MazeGymEnv(maze_size, participant_id, enable_enemy, enable_trap_boost, max_steps)\n",
    "agent = QLearningAgent(maze_size, num_actions)\n",
    "\n",
    "start_episode = 0\n",
    "best_reward = -np.inf\n",
    "best_q_table = None\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(\"Checkpoint found. Loading...\")\n",
    "    with open(save_path, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        agent.q_table = checkpoint['q_table']\n",
    "        start_episode = checkpoint['episode']\n",
    "        epsilon = checkpoint['epsilon']\n",
    "        best_q_table = checkpoint.get('best_q_table', agent.q_table.copy())\n",
    "        best_reward = checkpoint.get('best_reward', -np.inf)\n",
    "        best_step_counter = checkpoint.get('best_step_counter', 0)\n",
    "    print(f\"Resuming from episode {start_episode} with epsilon {epsilon:.4f}, best reward {best_reward:.2f} and best step {best_step_counter}\")\n",
    "else:\n",
    "    epsilon = 1.0\n",
    "\n",
    "try:\n",
    "    for episode in range(start_episode, num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        visited_states = set()\n",
    "        episode_reward = 0\n",
    "        step_counter = 0\n",
    "\n",
    "        while not done and step_counter < max_steps:\n",
    "            action = agent.choose_action(env, state, epsilon)\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "            if next_state in visited_states:\n",
    "                reward += REWARD_REVISIT\n",
    "            visited_states.add(next_state)\n",
    "\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            step_counter += 1\n",
    "\n",
    "            if state == env.goal:\n",
    "                done = True\n",
    "\n",
    "        if episode_reward > best_reward:\n",
    "            best_reward = episode_reward\n",
    "            best_q_table = agent.q_table.copy()\n",
    "            best_step_counter = step_counter\n",
    "            with open(save_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'q_table': agent.q_table,\n",
    "                    'episode': episode,\n",
    "                    'epsilon': epsilon,\n",
    "                    'best_q_table': best_q_table,\n",
    "                    'best_reward': best_reward,\n",
    "                    'best_step_counter': best_step_counter\n",
    "                }, f)\n",
    "            print(f\"New best at episode {episode}: {step_counter} steps and Reward {best_reward:.2f}\")\n",
    "\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "        if episode % 1000 == 0:\n",
    "            print(f\"Episode {episode}/{num_episodes} - Epsilon: {epsilon:.4f} - Total Steps: {step_counter} - Episode Reward: {episode_reward:.2f} - Best Reward: {best_reward:.2f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted.\")\n",
    "    print(f\"Interrupted at episode {episode} with epsilon: {epsilon:.4f}, Total Steps: {step_counter}, Episode Reward: {episode_reward:.2f}\")\n",
    "else:\n",
    "    print(f\"\\nTraining completed. Total episodes: {episode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "bVahczp5tZTY"
   },
   "outputs": [],
   "source": [
    "def test_agent(env, agent, animated, delay, theme):\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    state = obs\n",
    "    path = [state]\n",
    "    visited_states = set()\n",
    "    total_reward = 0\n",
    "    reward_breakdown = {\n",
    "        'goal':     {'count': 0, 'reward': 0.0},\n",
    "        'trap':     {'count': 0, 'reward': 0.0},\n",
    "        'boost':    {'count': 0, 'reward': 0.0},\n",
    "        'obstacle': {'count': 0, 'reward': 0.0},\n",
    "        'step':     {'count': 0, 'reward': 0.0},\n",
    "        'revisit':  {'count': 0, 'reward': 0.0}\n",
    "    }\n",
    "    caught_by_enemy = False\n",
    "    success = False\n",
    "    interrupted = False\n",
    "\n",
    "    try:\n",
    "        for step in range(env.max_steps):\n",
    "            visited_states.add(state)\n",
    "\n",
    "            action = agent.choose_action(env, state, epsilon=0.0)\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "            if info.get('terminated_by') == 'enemy':\n",
    "                caught_by_enemy = True\n",
    "                reward_breakdown.setdefault('enemy', {'count': 0, 'reward': 0.0})\n",
    "                reward_breakdown['enemy']['count'] += 1\n",
    "                reward_breakdown['enemy']['reward'] += reward\n",
    "                total_reward += reward\n",
    "                path.append(next_state)\n",
    "                break\n",
    "            else:\n",
    "                if (next_state == state) and (reward == REWARD_OBSTACLE):\n",
    "                    reward_breakdown['obstacle']['count'] += 1\n",
    "                    reward_breakdown['obstacle']['reward'] += REWARD_OBSTACLE\n",
    "                elif next_state == env.goal:\n",
    "                    reward_breakdown['goal']['count'] += 1\n",
    "                    reward_breakdown['goal']['reward'] += REWARD_GOAL\n",
    "                elif next_state in env.trap_cells:\n",
    "                    reward_breakdown['trap']['count'] += 1\n",
    "                    reward_breakdown['trap']['reward'] += REWARD_TRAP\n",
    "                elif next_state in env.boost_cells:\n",
    "                    reward_breakdown['boost']['count'] += 1\n",
    "                    reward_breakdown['boost']['reward'] += REWARD_BOOST\n",
    "                elif next_state in visited_states:\n",
    "                    reward += REWARD_REVISIT\n",
    "                    reward_breakdown['revisit']['count'] += 1\n",
    "                    reward_breakdown['revisit']['reward'] += REWARD_REVISIT\n",
    "                reward_breakdown['step']['count'] += 1\n",
    "                reward_breakdown['step']['reward'] += REWARD_STEP\n",
    "\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            path.append(state)\n",
    "\n",
    "            if animated:\n",
    "                env.render(path, theme)\n",
    "                print(f\"\\nTotal Allowed Ateps: {env.max_steps}\")\n",
    "                print(f\"Current Reward: {total_reward:.2f}\")\n",
    "                print(\"Live Reward Breakdown:\")\n",
    "                df = pd.DataFrame.from_dict(reward_breakdown, orient='index')\n",
    "                print(df)\n",
    "                time.sleep(delay)\n",
    "\n",
    "            if done or truncated:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        interrupted = True\n",
    "\n",
    "    if state == env.goal:\n",
    "        success = True\n",
    "\n",
    "    return path, total_reward, reward_breakdown, success, interrupted, caught_by_enemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NkA-fGy4EAS",
    "outputId": "a0658c4e-39a0-4fe6-ac6c-f449d295ea6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint found. Loading best Q-table for testing...\n",
      "Best Q-table loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "env = MazeGymEnv(maze_size, participant_id, enable_enemy, enable_trap_boost, max_steps)\n",
    "agent = QLearningAgent(maze_size, num_actions)\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(\"Checkpoint found. Loading best Q-table for testing...\")\n",
    "    with open(save_path, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        best_q_table = checkpoint.get('best_q_table', checkpoint['q_table'])\n",
    "        agent.q_table = best_q_table\n",
    "    print(\"Best Q-table loaded successfully.\")\n",
    "else:\n",
    "    print(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚪 🚶 🚶 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛\n",
      "⬛ ⬛ 🚧 🚧 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ 🚶 ⬛ ⬛ 🚧 🚧 ⬛ ⬛ 🚧 ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ 🚧 🚧 ⬛ 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ 🚧 ⬛ 🚧 ⬛\n",
      "⬛ 🚧 ⬛ ⬛ ⬛ 🚶 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧\n",
      "⬛ 🚧 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "🚧 🚧 ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ 🚶 🚶 ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "🚧 ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ 🚶 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚧\n",
      "⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 🚧 ⬛ ⬛ 🚧 ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 🚶 🚶 🚶 ⬛ ⬛ ⬛ ⬛ ⬛\n",
      "⬛ 🚧 ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ 🚧 ⬛ 🚶 🚶 ⬛ ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ ⬛ ⬛ 🚶 🚶 ⬛ ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚧 ⬛ 🚧 ⬛ ⬛ ⬛ 🚧 ⬛ 🚶 🚶 ⬛ ⬛\n",
      "⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ 🚶 🚶 🧑\n",
      "\n",
      "🏚️ Safehouse reached! You escaped the horde!\n",
      "         Count  Reward\n",
      "Goal         1    10.0\n",
      "Trap         0     0.0\n",
      "Boost        0     0.0\n",
      "Obstacle     0     0.0\n",
      "Step        38  -380.0\n",
      "Revisit      0     0.0\n",
      "Total           -370.0\n",
      "\n",
      "Total Allowed Ateps: 2000\n"
     ]
    }
   ],
   "source": [
    "# Run test.\n",
    "\n",
    "theme = random.choice(list(THEMES.keys()))\n",
    "plot_delay = 0.1  # Adjust delay as needed\n",
    "\n",
    "path, total_reward, reward_breakdown, success, interrupted, caught_by_enemy = test_agent(env, agent, animated=True, delay=plot_delay, theme=theme)\n",
    "\n",
    "env.render(path, theme=theme)\n",
    "env.print_final_message(success, interrupted, caught=caught_by_enemy, theme=theme)\n",
    "\n",
    "reward_df = pd.DataFrame.from_dict(reward_breakdown, orient='index')\n",
    "reward_df.index = reward_df.index.str.title()\n",
    "reward_df = reward_df.rename(columns={'count': 'Count', 'reward': 'Reward'})\n",
    "total_row = pd.DataFrame({\n",
    "    'Count': [''],\n",
    "    'Reward': [reward_df['Reward'].sum()]\n",
    "}, index=['Total'])\n",
    "reward_df = pd.concat([reward_df, total_row])\n",
    "\n",
    "print(reward_df)\n",
    "print(f\"\\nTotal Allowed Ateps: {max_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 4)\n",
      "State (0, 0);: [-1045.71491354 -1588.71383293 -1066.48345877  -847.42825257]\n",
      "State (0, 1);: [-1110.90869152 -1354.90296043 -1046.20190577  -836.96333848]\n",
      "State (0, 2);: [-1078.13480395 -1061.11394506 -1156.21437281  -801.57311506]\n",
      "State (0, 3);: [-1033.8684006  -1022.3933811  -1153.06060449  -780.56935988]\n",
      "State (0, 4);: [-1025.70115657  -773.90939208 -1058.4832848  -1086.49868792]\n",
      "State (0, 5);: [-1429.28577362  -889.57953795 -1630.96631373 -1753.5162431 ]\n",
      "State (0, 6);: [-1836.53858659 -1640.03081151 -1930.50661344 -1776.60586701]\n",
      "State (0, 7);: [-1812.62586314 -1767.83393022 -1917.32028001 -1785.15914125]\n",
      "State (0, 8);: [-1791.62936955 -1778.76181607 -1865.8873202  -1773.59687722]\n",
      "State (0, 9);: [-1762.09808071 -1747.31839474 -1857.13135565 -1740.1687516 ]\n",
      "State (0, 10);: [-1722.89495011 -1729.16661973 -1806.13201191 -1741.43026763]\n",
      "State (0, 11);: [-1751.23032331 -1735.6525532  -1773.1822175  -1752.51691642]\n",
      "State (0, 12);: [0. 0. 0. 0.]\n",
      "State (0, 13);: [-1683.42788579 -1740.83301294 -1687.62668876 -1672.95882737]\n",
      "State (0, 14);: [-1626.29098966 -1655.60081829 -1683.38247437 -1631.75950039]\n",
      "State (0, 15);: [-1590.9292419  -1650.77150766 -1621.71993956 -1592.41230311]\n",
      "State (0, 16);: [-1644.41241658 -1672.5612382  -1648.3196762  -1642.29489083]\n",
      "State (0, 17);: [-1656.08565182 -1643.06185249 -1664.06824784 -1652.94213871]\n",
      "State (0, 18);: [0. 0. 0. 0.]\n",
      "State (0, 19);: [-1740.97876222 -1727.04256406 -1722.39173516 -1734.90148984]\n",
      "State (1, 0);: [-1766.80960071 -1451.61291761 -1939.46374538 -1865.03629056]\n",
      "State (1, 1);: [-1644.80397872 -1225.10800253 -1883.50154919 -1866.56743868]\n",
      "State (1, 2);: [0. 0. 0. 0.]\n",
      "State (1, 3);: [0. 0. 0. 0.]\n",
      "State (1, 4);: [-1103.65941004  -936.09089144  -987.56375974  -752.97067603]\n",
      "State (1, 5);: [-1104.80669813  -702.18148231 -1057.1208502  -1234.83283001]\n",
      "State (1, 6);: [-1803.84529606 -1667.56167296 -1045.54944228 -1653.00643192]\n",
      "State (1, 7);: [-1761.99596288 -1637.75461514 -1867.952986   -1741.58795626]\n",
      "State (1, 8);: [-1777.47828958 -1720.28985628 -1845.03405378 -1716.39783669]\n",
      "State (1, 9);: [-1751.55685902 -1725.03216346 -1846.20976198 -1715.11635407]\n",
      "State (1, 10);: [-1751.99563807 -1709.15918382 -1804.07802404 -1672.57961828]\n",
      "State (1, 11);: [-1694.55004216 -1672.89101799 -1769.75633881 -1661.33272048]\n",
      "State (1, 12);: [-1688.87491807 -1668.18648755 -1762.96992069 -1652.66451913]\n",
      "State (1, 13);: [-1646.81747577 -1603.90758261 -1762.43255153 -1606.11270643]\n",
      "State (1, 14);: [-1645.2334499  -1632.56104108 -1632.96511252 -1611.34097124]\n",
      "State (1, 15);: [-1593.188801   -1595.30886493 -1665.32778326 -1610.47128737]\n",
      "State (1, 16);: [0. 0. 0. 0.]\n",
      "State (1, 17);: [-1628.45569964 -1604.94156517 -1600.95704115 -1598.40096923]\n",
      "State (1, 18);: [-1609.86289498 -1595.71246187 -1618.74614813 -1665.86802927]\n",
      "State (1, 19);: [-1675.73123202 -1642.31644515 -1664.92258884 -1671.32483539]\n",
      "State (2, 0);: [-1979.56698288 -1843.34170882 -1894.94883293 -1285.24263057]\n",
      "State (2, 1);: [-1761.67489528 -1792.47317159 -1717.37558473 -1081.43676676]\n",
      "State (2, 2);: [-1499.07510277 -1667.86743636 -1744.32090517  -974.91086425]\n",
      "State (2, 3);: [-1677.48205377 -1606.07452084 -1736.14588664  -898.26539947]\n",
      "State (2, 4);: [-1237.7169521   -820.20842278 -1780.67163195 -1157.69974221]\n",
      "State (2, 5);: [-1032.49789458  -678.25703383  -984.6980862  -1309.49053151]\n",
      "State (2, 6);: [-1757.0373977  -1027.50119488 -1781.15692693 -1699.15891003]\n",
      "State (2, 7);: [-1765.71804364 -1660.46954671 -1713.8350311  -1558.22710028]\n",
      "State (2, 8);: [-1762.37884506 -1716.98322488 -1793.21132917 -1505.01650048]\n",
      "State (2, 9);: [-1752.79627055 -1727.32933055 -1802.10108353 -1422.92527252]\n",
      "State (2, 10);: [-1706.81114932 -1326.41393752 -1823.63744098 -1631.0457004 ]\n",
      "State (2, 11);: [-1701.11610409 -1676.17186553 -1660.51196854 -1608.91373584]\n",
      "State (2, 12);: [-1666.01697988 -1662.74467733 -1736.28159079 -1563.59669904]\n",
      "State (2, 13);: [-1595.52752811 -1530.38434663 -1718.66116122 -1649.71808834]\n",
      "State (2, 14);: [-1675.64552661 -1659.4732288  -1669.85386342 -1614.38958852]\n",
      "State (2, 15);: [-1603.57863216 -1620.43302522 -1632.05933195 -1577.57353309]\n",
      "State (2, 16);: [-1602.96177655 -1566.28322661 -1630.51139514 -1577.33441665]\n",
      "State (2, 17);: [-1569.03847655 -1547.26519517 -1617.00941981 -1591.19718854]\n",
      "State (2, 18);: [-1559.90484396 -1554.61839699 -1593.77416559 -1568.49302832]\n",
      "State (2, 19);: [-1609.64789329 -1603.9098535  -1608.50195058 -1610.79968642]\n",
      "State (3, 0);: [-1995.50195596 -1853.65764449 -1914.54781813 -1838.95276592]\n",
      "State (3, 1);: [-1889.41688578 -1909.69208973 -1877.99854507 -1692.20710225]\n",
      "State (3, 2);: [-1768.63726161 -1848.19889375 -1953.90469298 -1401.07307593]\n",
      "State (3, 3);: [-1652.93400553 -1780.22075806 -1855.24927068 -1062.4485569 ]\n",
      "State (3, 4);: [-1555.79550532  -758.05588585 -1465.04042762  -968.13806582]\n",
      "State (3, 5);: [-1053.79117574  -651.32700133  -965.81510387 -1017.41736546]\n",
      "State (3, 6);: [-1627.16683442  -790.33577461 -1607.77166645 -1542.17824436]\n",
      "State (3, 7);: [-1758.66799074 -1225.35576812 -1697.52253772 -1737.09442885]\n",
      "State (3, 8);: [0. 0. 0. 0.]\n",
      "State (3, 9);: [0. 0. 0. 0.]\n",
      "State (3, 10);: [-1707.25860144 -1224.29717645 -1683.62950914 -1674.14144913]\n",
      "State (3, 11);: [-1670.25255565 -1629.60194477 -1680.05475049 -1708.41360556]\n",
      "State (3, 12);: [0. 0. 0. 0.]\n",
      "State (3, 13);: [-1682.13284183 -1503.04439544 -1616.43953619 -1624.26360577]\n",
      "State (3, 14);: [0. 0. 0. 0.]\n",
      "State (3, 15);: [-1607.79807224 -1560.46843635 -1577.78321006 -1597.83292709]\n",
      "State (3, 16);: [-1640.2951062  -1590.08808039 -1590.15457337 -1533.51861901]\n",
      "State (3, 17);: [-1601.55110736 -1476.38223103 -1568.41260213 -1555.29179268]\n",
      "State (3, 18);: [-1580.11712198 -1573.26582899 -1533.97127037 -1572.96938507]\n",
      "State (3, 19);: [-1607.54778921 -1568.19976534 -1597.14986046 -1582.10655058]\n",
      "State (4, 0);: [-2005.0774994  -1805.06544936 -1873.03287997 -1900.24008303]\n",
      "State (4, 1);: [-1960.99203114 -1927.49365717 -1875.46964837 -1943.8264581 ]\n",
      "State (4, 2);: [0. 0. 0. 0.]\n",
      "State (4, 3);: [0. 0. 0. 0.]\n",
      "State (4, 4);: [-1295.99038048 -1153.19378283 -1199.03345238  -698.11824707]\n",
      "State (4, 5);: [-940.90783787 -619.08129662 -926.45180149 -763.01801799]\n",
      "State (4, 6);: [-1434.08171923  -689.2481813  -1272.27991999 -1307.53416707]\n",
      "State (4, 7);: [-1648.81294982  -818.61009819 -1466.037638   -1538.64807199]\n",
      "State (4, 8);: [-1665.32093407 -1248.03734227 -1791.90827989 -1590.41804268]\n",
      "State (4, 9);: [-1629.05672578 -1550.97179134 -1679.32009305 -1337.91287385]\n",
      "State (4, 10);: [-1608.76599384 -1073.29364063 -1580.00771079 -1615.02302893]\n",
      "State (4, 11);: [-1727.86042597 -1540.16787851 -1650.82381731 -1654.00503459]\n",
      "State (4, 12);: [0. 0. 0. 0.]\n",
      "State (4, 13);: [-1665.91308849 -1514.50002526 -1581.61375427 -1464.37638937]\n",
      "State (4, 14);: [-1537.39473714 -1422.03575283 -1606.86188593 -1494.87638611]\n",
      "State (4, 15);: [-1577.17018486 -1454.2759134  -1560.5153287  -1536.18165053]\n",
      "State (4, 16);: [0. 0. 0. 0.]\n",
      "State (4, 17);: [-1612.55153527 -1399.38154369 -1548.22187655 -1542.61845694]\n",
      "State (4, 18);: [0. 0. 0. 0.]\n",
      "State (4, 19);: [-1654.2469576  -1515.40698202 -1516.13680447 -1558.10663884]\n",
      "State (5, 0);: [-1977.48438604 -1777.3212433  -1837.63370011 -1860.05498867]\n",
      "State (5, 1);: [0. 0. 0. 0.]\n",
      "State (5, 2);: [-1766.80043139 -1795.23963894 -1762.65856179 -1776.9745593 ]\n",
      "State (5, 3);: [-1800.69007499 -1739.0285492  -1771.24319111 -1790.76462135]\n",
      "State (5, 4);: [-1564.46872516 -1695.11011484 -1729.34226847  -858.24959062]\n",
      "State (5, 5);: [-999.08779839 -921.74455973 -957.58168662 -603.03281014]\n",
      "State (5, 6);: [-821.06695999 -769.3950755  -877.76155446 -581.77271476]\n",
      "State (5, 7);: [-911.54336036 -560.38130756 -899.69482482 -790.76528613]\n",
      "State (5, 8);: [-1645.46375152 -1372.8658684  -1474.29870283  -673.13449056]\n",
      "State (5, 9);: [-1518.36598862  -634.59419847 -1477.00897167 -1309.53656752]\n",
      "State (5, 10);: [-1549.7739571   -889.52076036 -1393.62554092 -1556.97381635]\n",
      "State (5, 11);: [-1688.66707048 -1539.13037938 -1596.52457123 -1508.00040985]\n",
      "State (5, 12);: [-1553.03852612 -1456.08725094 -1646.4011707  -1540.82993644]\n",
      "State (5, 13);: [-1570.32439472 -1476.44166974 -1543.99303561 -1520.6427396 ]\n",
      "State (5, 14);: [-1540.7259954  -1353.66097937 -1579.55001152 -1472.54791431]\n",
      "State (5, 15);: [-1510.00019404 -1363.5720304  -1497.51494287 -1479.03166991]\n",
      "State (5, 16);: [-1481.92672774 -1367.17425122 -1516.97626962 -1450.45963763]\n",
      "State (5, 17);: [-1597.46658599 -1300.62299811 -1482.14953904 -1516.07459384]\n",
      "State (5, 18);: [-1497.07849926 -1490.54376301 -1480.30714448 -1571.45018705]\n",
      "State (5, 19);: [-1544.97155247 -1536.59172017 -1525.18188399 -1530.43833549]\n",
      "State (6, 0);: [-1905.74058456 -1752.36862779 -1793.70750475 -1771.98185654]\n",
      "State (6, 1);: [-1801.37596778 -1773.66434595 -1890.59684803 -1764.69566852]\n",
      "State (6, 2);: [-1744.50516355 -1723.50593875 -1820.39397453 -1751.47715215]\n",
      "State (6, 3);: [-1753.04778667 -1702.77424341 -1735.80929503 -1753.34817895]\n",
      "State (6, 4);: [-1744.00894037 -1650.2292011  -1723.14354124 -1717.65637293]\n",
      "State (6, 5);: [-1653.86505514 -1515.9561483  -1701.26940427  -776.84826975]\n",
      "State (6, 6);: [-1281.08559065 -1235.88095038 -1382.23667464  -664.58775454]\n",
      "State (6, 7);: [-810.39644732 -627.76165251 -727.39573502 -540.89021218]\n",
      "State (6, 8);: [-842.53040513 -534.74957744 -869.79644766 -706.64102403]\n",
      "State (6, 9);: [-1083.11467255  -638.83768675 -1055.59804305  -921.33788051]\n",
      "State (6, 10);: [-1514.26979423  -648.20870785 -1318.67389433 -1532.99307036]\n",
      "State (6, 11);: [-1630.7277762  -1424.75879886 -1501.99960234 -1522.33969273]\n",
      "State (6, 12);: [-1561.8477101  -1506.31431433 -1569.72657587 -1373.86129845]\n",
      "State (6, 13);: [-1507.0917372  -1271.68404905 -1565.32124349 -1464.26802476]\n",
      "State (6, 14);: [-1532.25260489 -1421.83988269 -1469.17751186 -1278.02599351]\n",
      "State (6, 15);: [-1542.76977618 -1377.10011857 -1521.37121794 -1197.78257483]\n",
      "State (6, 16);: [-1472.1483183  -1081.61031371 -1480.96149369 -1376.46034356]\n",
      "State (6, 17);: [-1500.40037527 -1189.25152843 -1324.60015046 -1448.40282612]\n",
      "State (6, 18);: [-1523.40382839 -1432.5849964  -1453.08083165 -1517.70843477]\n",
      "State (6, 19);: [-1551.93684702 -1495.50809131 -1502.24472491 -1517.23560332]\n",
      "State (7, 0);: [-1849.25583261 -1775.09574674 -1791.16526369 -1737.38014282]\n",
      "State (7, 1);: [-1790.38043866 -1764.24174738 -1858.4559612  -1718.61826981]\n",
      "State (7, 2);: [-1798.98783421 -1721.29571999 -1782.7357149  -1669.72580043]\n",
      "State (7, 3);: [-1761.75179335 -1720.03309968 -1777.25401593 -1578.61398146]\n",
      "State (7, 4);: [-1736.43147159 -1680.27773947 -1730.81077094 -1387.20020923]\n",
      "State (7, 5);: [-1740.63389847 -1665.2935756  -1695.79929423 -1125.38277045]\n",
      "State (7, 6);: [-1443.78046622 -1624.35860787 -1582.12940498  -790.77099732]\n",
      "State (7, 7);: [-1114.96210556 -1316.38556199 -1254.49229713  -553.48293023]\n",
      "State (7, 8);: [-772.62527434 -754.00758063 -743.51102502 -535.72091058]\n",
      "State (7, 9);: [-674.58859654 -497.18695339 -719.99891856 -619.13524007]\n",
      "State (7, 10);: [-1441.25917647  -521.47220662 -1029.03926513 -1393.38599871]\n",
      "State (7, 11);: [-1572.41276287 -1083.3753017  -1531.03960734 -1512.0315441 ]\n",
      "State (7, 12);: [-1568.42077896 -1533.93576944 -1575.33672228 -1449.93053366]\n",
      "State (7, 13);: [-1537.60280387 -1183.97630417 -1536.58036961 -1400.18823368]\n",
      "State (7, 14);: [-1466.68972381 -1272.44906787 -1471.53151569 -1403.06871749]\n",
      "State (7, 15);: [-1459.08844174 -1202.47739688 -1456.46257719 -1394.2173417 ]\n",
      "State (7, 16);: [-1408.1328111  -1020.64727763 -1376.4183674  -1182.54669898]\n",
      "State (7, 17);: [-1350.88677738  -987.16633148 -1290.17676271 -1434.08343098]\n",
      "State (7, 18);: [-1482.58565813 -1450.68185782 -1308.60596213 -1494.25014422]\n",
      "State (7, 19);: [-1495.7656858  -1513.80587514 -1482.24648618 -1505.10108914]\n",
      "State (8, 0);: [-1815.7023758  -1747.91731279 -1782.58526352 -1792.87570574]\n",
      "State (8, 1);: [-1809.38185829 -1725.93654791 -1784.82748217 -1725.97817147]\n",
      "State (8, 2);: [-1761.40589013 -1710.13940749 -1773.84206836 -1758.47636245]\n",
      "State (8, 3);: [0. 0. 0. 0.]\n",
      "State (8, 4);: [-1729.34046298 -1669.42633232 -1715.3173171  -1682.49353249]\n",
      "State (8, 5);: [-1661.96507281 -1631.69250059 -1676.29976945 -1660.97880017]\n",
      "State (8, 6);: [-1691.6996192  -1613.33912396 -1658.79515588 -1619.47188012]\n",
      "State (8, 7);: [-1652.53730946 -1605.21786307 -1636.0756459   -995.03062755]\n",
      "State (8, 8);: [-1065.43576819 -1128.37716892 -1543.4119812   -630.38080042]\n",
      "State (8, 9);: [-716.56388429 -463.8574079  -698.09757233 -578.8632022 ]\n",
      "State (8, 10);: [-1031.98872901  -468.47770191  -828.48820053  -999.29759638]\n",
      "State (8, 11);: [-1509.52051407  -694.40775281 -1274.70560555 -1388.5388785 ]\n",
      "State (8, 12);: [0. 0. 0. 0.]\n",
      "State (8, 13);: [-1518.19422886 -1045.22824859 -1395.56916025 -1362.54519936]\n",
      "State (8, 14);: [-1452.87791728 -1077.85047377 -1371.08794115 -1315.45556436]\n",
      "State (8, 15);: [-1417.80115657 -1018.86922205 -1386.38643828 -1168.96501716]\n",
      "State (8, 16);: [-1331.35689099  -921.24663961 -1325.65251538 -1075.43383426]\n",
      "State (8, 17);: [-1353.57359953  -835.9887497  -1209.71461109 -1201.8606387 ]\n",
      "State (8, 18);: [0. 0. 0. 0.]\n",
      "State (8, 19);: [-1598.47638849 -1533.92756243 -1548.24735363 -1538.52748539]\n",
      "State (9, 0);: [-1812.48007032 -1804.85105579 -1793.6565619  -1735.30892905]\n",
      "State (9, 1);: [-1839.78429319 -1737.17920293 -1832.45610621 -1692.79845825]\n",
      "State (9, 2);: [-1830.6324768  -1707.58024154 -1804.53001413 -1657.37267194]\n",
      "State (9, 3);: [-1688.96687913 -1651.90613945 -1776.1021834  -1642.57334981]\n",
      "State (9, 4);: [-1780.05338769 -1605.23098638 -1642.03224531 -1636.92806297]\n",
      "State (9, 5);: [-1728.97043346 -1606.77226792 -1687.82407577 -1603.36314704]\n",
      "State (9, 6);: [-1737.45553266 -1585.00261857 -1651.4791866  -1519.69552246]\n",
      "State (9, 7);: [-1638.35804733 -1441.59170853 -1636.88339399 -1607.06834914]\n",
      "State (9, 8);: [0. 0. 0. 0.]\n",
      "State (9, 9);: [-717.44276039 -560.0367869  -605.36768381 -437.69368548]\n",
      "State (9, 10);: [-613.54793529 -423.08561829 -685.23478069 -562.63529341]\n",
      "State (9, 11);: [-1203.12414132  -914.3170736  -1071.13229448  -487.16453353]\n",
      "State (9, 12);: [ -953.62918143  -443.56780216 -1026.82504772 -1084.43740855]\n",
      "State (9, 13);: [-1463.53478922 -1367.89228457 -1134.76152494  -893.09498504]\n",
      "State (9, 14);: [-1329.08735161 -1130.68484169 -1290.98128878  -780.98320939]\n",
      "State (9, 15);: [-1258.47957866  -693.51316124 -1224.37754698 -1078.94923426]\n",
      "State (9, 16);: [-1263.73514014  -752.7992577  -1203.73252988 -1014.30965104]\n",
      "State (9, 17);: [-1202.57076791  -718.2727895  -1112.19103516  -999.11087789]\n",
      "State (9, 18);: [-1140.84850239  -770.00052227 -1177.3204086  -1094.61791167]\n",
      "State (9, 19);: [0. 0. 0. 0.]\n",
      "State (10, 0);: [-1896.91888385 -1898.66786515 -1890.81310347 -1887.63215483]\n",
      "State (10, 1);: [0. 0. 0. 0.]\n",
      "State (10, 2);: [0. 0. 0. 0.]\n",
      "State (10, 3);: [-1754.77615893 -1620.84235322 -1650.23905118 -1655.95794146]\n",
      "State (10, 4);: [-1692.61288278 -1578.43007706 -1645.35807904 -1657.90744149]\n",
      "State (10, 5);: [-1654.45554112 -1597.11854429 -1617.32106111 -1605.58704495]\n",
      "State (10, 6);: [-1647.04088127 -1637.80910025 -1614.87805764 -1559.24535269]\n",
      "State (10, 7);: [-1647.69371469 -1308.48693549 -1660.58484374 -1496.36688823]\n",
      "State (10, 8);: [-1550.16212704 -1186.68439399 -1541.59296976 -1496.24698652]\n",
      "State (10, 9);: [-1060.5910804   -876.99793967 -1348.24934707  -486.26033097]\n",
      "State (10, 10);: [-654.69198611 -416.07533621 -591.24807617 -521.83764302]\n",
      "State (10, 11);: [-1080.73380711  -837.19908684 -1006.43940402  -453.27457718]\n",
      "State (10, 12);: [-825.0257157  -397.96061236 -886.36866926 -649.75012806]\n",
      "State (10, 13);: [0. 0. 0. 0.]\n",
      "State (10, 14);: [-1346.42416526  -935.85353815 -1296.49276799 -1171.4799444 ]\n",
      "State (10, 15);: [-1221.67011535 -1101.16567447 -1131.50368551  -610.44698927]\n",
      "State (10, 16);: [-1044.9657383   -549.6288503  -1040.22877603  -749.64319463]\n",
      "State (10, 17);: [-1148.42505123  -765.75478561 -1039.23930588  -611.87710557]\n",
      "State (10, 18);: [-1006.50096933  -532.65669658  -956.79341274 -1059.17110611]\n",
      "State (10, 19);: [-1170.72717611 -1053.82068711  -881.24661758 -1149.43886682]\n",
      "State (11, 0);: [0. 0. 0. 0.]\n",
      "State (11, 1);: [0. 0. 0. 0.]\n",
      "State (11, 2);: [-1701.96993358 -1670.98888438 -1684.23700651 -1693.46220093]\n",
      "State (11, 3);: [-1691.39560833 -1603.46168737 -1647.02488547 -1616.72377752]\n",
      "State (11, 4);: [-1706.80061618 -1546.80325323 -1648.4931182  -1588.17141186]\n",
      "State (11, 5);: [-1691.1375014  -1545.81183316 -1589.27400582 -1593.14169088]\n",
      "State (11, 6);: [0. 0. 0. 0.]\n",
      "State (11, 7);: [-1623.44421379 -1471.75002264 -1495.545964   -1173.3065263 ]\n",
      "State (11, 8);: [-1531.53618264  -971.05156936 -1463.57789911 -1111.94894992]\n",
      "State (11, 9);: [-1212.5646929  -1117.2744655  -1301.58389888  -593.02339699]\n",
      "State (11, 10);: [-648.94932317 -493.93799108 -717.62356317 -380.78272787]\n",
      "State (11, 11);: [-509.1521414  -355.84544508 -623.83957259 -408.92037056]\n",
      "State (11, 12);: [-715.93825987 -340.11504443 -527.27080685 -888.01352855]\n",
      "State (11, 13);: [-1182.38709787  -732.51097947 -1084.35746918 -1206.0362553 ]\n",
      "State (11, 14);: [-1322.51564663  -734.3383091  -1231.23052258 -1158.47101001]\n",
      "State (11, 15);: [0. 0. 0. 0.]\n",
      "State (11, 16);: [-944.98842067 -498.00362433 -875.97196249 -818.64122783]\n",
      "State (11, 17);: [-1011.5549276   -750.69180264  -954.9873519   -569.58329792]\n",
      "State (11, 18);: [-814.673825   -435.79470146 -754.09316976 -845.89427414]\n",
      "State (11, 19);: [-1123.28145922  -933.8875878   -668.6312211  -1012.98232537]\n",
      "State (12, 0);: [-1722.33277181 -1722.10137563 -1737.68172842 -1715.26773414]\n",
      "State (12, 1);: [-1602.725817   -1576.11931655 -1697.47861204 -1683.17749528]\n",
      "State (12, 2);: [-1648.03942731 -1614.43592555 -1593.40170952 -1657.98142381]\n",
      "State (12, 3);: [-1626.49222147 -1606.13970451 -1590.09022106 -1612.59010504]\n",
      "State (12, 4);: [-1644.59894914 -1518.7200138  -1635.76824641 -1551.77387607]\n",
      "State (12, 5);: [-1639.7010345  -1594.1163386  -1631.76020363 -1488.87083089]\n",
      "State (12, 6);: [-1526.55889932 -1461.79055668 -1621.28960425 -1548.74613434]\n",
      "State (12, 7);: [0. 0. 0. 0.]\n",
      "State (12, 8);: [-1449.36103327 -1380.37683396 -1370.42919751  -821.92460644]\n",
      "State (12, 9);: [-1325.87781339 -1162.14114403 -1334.63658509  -605.56986688]\n",
      "State (12, 10);: [-802.46113183 -428.26058025 -911.41158757 -711.1626667 ]\n",
      "State (12, 11);: [-605.23078704 -375.29065617 -512.71051172 -317.39914393]\n",
      "State (12, 12);: [-574.88802564 -286.04389383 -535.64467966 -659.38078616]\n",
      "State (12, 13);: [-1099.15358344 -1055.08745457  -897.27631637  -541.46157212]\n",
      "State (12, 14);: [ -996.14942425  -771.17479984 -1003.94820454  -473.97206636]\n",
      "State (12, 15);: [-828.72330724 -670.86989734 -995.55212683 -399.53877566]\n",
      "State (12, 16);: [-764.48226126 -628.84838626 -791.00831135 -345.6433386 ]\n",
      "State (12, 17);: [-741.67022098 -529.32473904 -768.03580598 -299.7461355 ]\n",
      "State (12, 18);: [-547.08736478 -255.11290924 -610.01884293 -635.70589671]\n",
      "State (12, 19);: [-944.64695272 -919.86126856 -554.44725615 -870.69662288]\n",
      "State (13, 0);: [0. 0. 0. 0.]\n",
      "State (13, 1);: [-1641.09218226 -1588.52336098 -1613.88852814 -1595.78947689]\n",
      "State (13, 2);: [-1697.27994343 -1563.37485784 -1590.17181614 -1614.1028428 ]\n",
      "State (13, 3);: [-1672.16367643 -1601.84566934 -1594.24967042 -1603.56010403]\n",
      "State (13, 4);: [-1693.26299171 -1459.73920376 -1612.63022485 -1542.62621824]\n",
      "State (13, 5);: [0. 0. 0. 0.]\n",
      "State (13, 6);: [-1559.44102605 -1470.41602751 -1489.03028903 -1458.22936384]\n",
      "State (13, 7);: [-1484.04742922 -1391.80369031 -1556.9614834  -1497.27403431]\n",
      "State (13, 8);: [0. 0. 0. 0.]\n",
      "State (13, 9);: [-1208.20293959 -1265.18626496 -1341.13090242  -734.17945257]\n",
      "State (13, 10);: [-863.21824976 -731.50521014 -879.39488631 -418.31197794]\n",
      "State (13, 11);: [-516.0911056  -416.89738502 -454.50265682 -372.26283142]\n",
      "State (13, 12);: [-408.37084008 -278.25592618 -461.2116295  -406.70081655]\n",
      "State (13, 13);: [0. 0. 0. 0.]\n",
      "State (13, 14);: [-1089.78041251  -789.86085382  -995.29202672  -585.07276342]\n",
      "State (13, 15);: [ -932.67853313  -409.52507614 -1014.68154435  -815.65917422]\n",
      "State (13, 16);: [-946.45328344 -859.61209833 -914.36775541 -513.78090279]\n",
      "State (13, 17);: [-694.13241521 -383.54642823 -786.61404042 -477.72149972]\n",
      "State (13, 18);: [-568.87828269 -220.07614044 -458.05566246 -396.13347008]\n",
      "State (13, 19);: [0. 0. 0. 0.]\n",
      "State (14, 0);: [-1621.39211816 -1635.44836536 -1624.65525996 -1626.37556254]\n",
      "State (14, 1);: [-1608.07521267 -1574.63712975 -1578.35482451 -1580.3187126 ]\n",
      "State (14, 2);: [-1651.37677794 -1524.14861292 -1572.48355634 -1584.37672526]\n",
      "State (14, 3);: [0. 0. 0. 0.]\n",
      "State (14, 4);: [-1627.4678618  -1431.06259867 -1511.71354831 -1463.32387032]\n",
      "State (14, 5);: [-1484.62627566 -1493.68325848 -1496.08475781 -1468.34753034]\n",
      "State (14, 6);: [-1507.93708566 -1446.1472401  -1522.01265379 -1399.05427542]\n",
      "State (14, 7);: [-1474.58924346 -1401.91134805 -1505.92663348 -1270.76963918]\n",
      "State (14, 8);: [-1396.1852763  -1375.49345232 -1451.03171036 -1137.4174799 ]\n",
      "State (14, 9);: [-1311.28397885 -1365.10348137 -1407.88116459  -884.26057092]\n",
      "State (14, 10);: [-1054.16249918 -1325.34095365 -1260.33074206  -523.81763424]\n",
      "State (14, 11);: [-767.42485566 -670.19820442 -775.45897374 -407.36112096]\n",
      "State (14, 12);: [-488.54752846 -263.27824136 -420.52501004 -387.37793509]\n",
      "State (14, 13);: [0. 0. 0. 0.]\n",
      "State (14, 14);: [-862.07566024 -605.21947171 -675.29061268 -284.16515709]\n",
      "State (14, 15);: [-754.57177917 -248.03718518 -729.47121723 -707.28694408]\n",
      "State (14, 16);: [0. 0. 0. 0.]\n",
      "State (14, 17);: [-611.03798245 -286.6607558  -554.98302109 -437.52852896]\n",
      "State (14, 18);: [-503.66889117 -191.76037789 -373.66633861 -401.46085896]\n",
      "State (14, 19);: [-520.31641846 -352.45829662 -615.30780976 -516.20654709]\n",
      "State (15, 0);: [-1660.60207166 -1569.80949611 -1571.67324841 -1621.95464943]\n",
      "State (15, 1);: [-1583.05399219 -1600.50532253 -1587.07421116 -1573.23718254]\n",
      "State (15, 2);: [-1580.88518543 -1500.99387516 -1621.83881059 -1544.93495001]\n",
      "State (15, 3);: [-1539.98014926 -1520.67777109 -1601.22289606 -1497.49996214]\n",
      "State (15, 4);: [-1531.63369652 -1433.91306207 -1548.30532084 -1411.85239892]\n",
      "State (15, 5);: [-1532.342214   -1412.20191565 -1509.35281501 -1423.99667395]\n",
      "State (15, 6);: [-1456.30778009 -1384.09253425 -1474.28973528 -1403.94259192]\n",
      "State (15, 7);: [-1439.5040626  -1369.75480561 -1472.09806808 -1353.11963672]\n",
      "State (15, 8);: [-1391.32192383 -1224.00234763 -1438.53139446 -1411.10485613]\n",
      "State (15, 9);: [-1400.66076784 -1408.07681693 -1426.10228456 -1342.24015045]\n",
      "State (15, 10);: [-1071.56679848 -1380.80308834 -1445.88238624 -1367.1946881 ]\n",
      "State (15, 11);: [0. 0. 0. 0.]\n",
      "State (15, 12);: [-483.28026344 -355.13073433 -363.17056027 -230.14829632]\n",
      "State (15, 13);: [-332.28739121 -300.4754091  -463.89363885 -213.15503869]\n",
      "State (15, 14);: [-318.50933105 -176.03961368 -431.44187505 -267.36292932]\n",
      "State (15, 15);: [-556.47992298 -201.2495956  -487.47977224 -446.17506397]\n",
      "State (15, 16);: [-559.04719123 -329.9603245  -579.98898045 -477.51794779]\n",
      "State (15, 17);: [-546.16924532 -247.64722497 -469.74743473 -309.88083862]\n",
      "State (15, 18);: [-500.74573082 -152.01863282 -364.00511521 -246.02681117]\n",
      "State (15, 19);: [-405.79942748 -230.43448115 -471.28041802 -362.25458282]\n",
      "State (16, 0);: [-1622.90948825 -1531.19624445 -1519.09153014 -1523.70074346]\n",
      "State (16, 1);: [0. 0. 0. 0.]\n",
      "State (16, 2);: [-1590.69120477 -1470.47317299 -1544.06037817 -1551.60925047]\n",
      "State (16, 3);: [0. 0. 0. 0.]\n",
      "State (16, 4);: [-1465.69555167 -1448.30766255 -1465.31260256 -1438.25637802]\n",
      "State (16, 5);: [-1485.09984579 -1457.55730775 -1471.27213948 -1366.74117312]\n",
      "State (16, 6);: [-1510.5400836  -1371.57948566 -1475.72938417 -1258.29695395]\n",
      "State (16, 7);: [-1417.34248224 -1336.73562897 -1392.07443097 -1137.31909773]\n",
      "State (16, 8);: [-1375.60003678  -989.24352357 -1382.00603918 -1276.25175888]\n",
      "State (16, 9);: [0. 0. 0. 0.]\n",
      "State (16, 10);: [-1424.69144338 -1352.66354562 -1409.10304234 -1450.83865305]\n",
      "State (16, 11);: [-1485.10568057 -1477.6066522  -1484.60165791 -1491.72677607]\n",
      "State (16, 12);: [0. 0. 0. 0.]\n",
      "State (16, 13);: [-564.88901821 -284.76297906 -500.40572945 -371.43782547]\n",
      "State (16, 14);: [-417.53538244 -238.67758644 -331.76424031 -152.32612253]\n",
      "State (16, 15);: [-339.71315557 -144.82154693 -354.01914099 -231.34096206]\n",
      "State (16, 16);: [-459.54166373 -175.76605812 -412.85150025 -256.46378303]\n",
      "State (16, 17);: [-384.11439801 -219.88792697 -409.63425824 -159.670652  ]\n",
      "State (16, 18);: [-369.26048907 -168.94535806 -334.57313451  -80.18635345]\n",
      "State (16, 19);: [-282.66324695  -61.60892097 -308.23745275 -226.59029792]\n",
      "State (17, 0);: [-1567.15857171 -1501.18119322 -1508.70206704 -1502.21505042]\n",
      "State (17, 1);: [-1517.77229367 -1526.24431831 -1515.32209248 -1526.45153086]\n",
      "State (17, 2);: [-1585.84580705 -1474.08226983 -1486.75098393 -1454.67543932]\n",
      "State (17, 3);: [-1464.50736426 -1460.68723927 -1504.65229545 -1440.19513241]\n",
      "State (17, 4);: [-1483.91259952 -1403.90419221 -1481.28414757 -1452.44187869]\n",
      "State (17, 5);: [0. 0. 0. 0.]\n",
      "State (17, 6);: [-1449.8622625  -1306.76483095 -1393.40466054 -1351.96403703]\n",
      "State (17, 7);: [-1387.78299572 -1179.61605632 -1382.17713012 -1334.12704269]\n",
      "State (17, 8);: [-1331.30298838 -1246.66048582 -1328.89320352  -865.04556911]\n",
      "State (17, 9);: [-1136.63190291  -773.46748485 -1276.62280428 -1300.43125203]\n",
      "State (17, 10);: [-1397.77213713 -1332.30813311 -1175.98696241 -1323.42266535]\n",
      "State (17, 11);: [0. 0. 0. 0.]\n",
      "State (17, 12);: [-879.75504757 -780.24436422 -878.92219487 -496.12647134]\n",
      "State (17, 13);: [-489.34812936 -464.65846514 -586.9010133  -272.07224351]\n",
      "State (17, 14);: [-369.34011014 -275.31262197 -322.82844926 -210.54428316]\n",
      "State (17, 15);: [-276.10215113 -127.46803924 -280.75684545 -116.21691515]\n",
      "State (17, 16);: [-254.50597938  -90.58869849 -328.075208   -115.94867412]\n",
      "State (17, 17);: [-188.99435972  -87.06591835 -295.97076315  -75.99567091]\n",
      "State (17, 18);: [-173.10452379  -65.58868064 -272.10569063  -78.30801273]\n",
      "State (17, 19);: [-253.43255862  -26.23205369 -178.89361145 -163.12934465]\n",
      "State (18, 0);: [-1551.71198128 -1530.8690342  -1519.04810096 -1531.15885309]\n",
      "State (18, 1);: [-1527.08519022 -1533.81297257 -1517.80790549 -1529.99860338]\n",
      "State (18, 2);: [-1496.8697606  -1475.40999206 -1504.808943   -1472.5928499 ]\n",
      "State (18, 3);: [-1458.53771365 -1460.46151475 -1485.15583932 -1454.09210548]\n",
      "State (18, 4);: [-1438.55798285 -1411.6826878  -1496.52907173 -1340.42629416]\n",
      "State (18, 5);: [-1370.27198202 -1370.07681739 -1394.75231194 -1224.57062567]\n",
      "State (18, 6);: [-1427.89793492 -1044.06433208 -1386.62812633 -1277.41248452]\n",
      "State (18, 7);: [-1396.9668582   -985.52718759 -1321.21861856 -1284.72909287]\n",
      "State (18, 8);: [0. 0. 0. 0.]\n",
      "State (18, 9);: [-1203.19460555  -689.96943335  -966.4339209   -983.81228715]\n",
      "State (18, 10);: [0. 0. 0. 0.]\n",
      "State (18, 11);: [-865.53966392 -794.40895955 -874.18734975 -666.01237567]\n",
      "State (18, 12);: [-843.56556229 -494.8542494  -879.96938871 -704.28264158]\n",
      "State (18, 13);: [-609.6929012  -381.82346985 -782.01832299 -626.67127891]\n",
      "State (18, 14);: [0. 0. 0. 0.]\n",
      "State (18, 15);: [-330.23033181 -143.24464166 -234.61169436  -93.1654461 ]\n",
      "State (18, 16);: [-137.13968235 -110.85326868 -319.59559644  -60.56194504]\n",
      "State (18, 17);: [-139.45017405  -39.99617946 -267.23300732  -77.4176655 ]\n",
      "State (18, 18);: [-181.17051953  -33.65208754 -115.69142576  -42.38498408]\n",
      "State (18, 19);: [-166.42822183   10.         -168.55214735 -100.09999335]\n",
      "State (19, 0);: [-1559.90317657 -1526.8630803  -1522.87362207 -1550.98474766]\n",
      "State (19, 1);: [-1537.92968272 -1474.04066463 -1503.52851907 -1483.96085285]\n",
      "State (19, 2);: [-1511.13478688 -1459.33708843 -1452.88428641 -1446.07227781]\n",
      "State (19, 3);: [-1489.20539873 -1427.31519769 -1427.7403461  -1393.50679087]\n",
      "State (19, 4);: [-1443.5738753  -1411.14995419 -1432.12345585 -1300.80746742]\n",
      "State (19, 5);: [-1368.19728257 -1295.15841499 -1446.47170522 -1128.31234274]\n",
      "State (19, 6);: [-1400.0195553  -1216.04388767 -1324.24578275  -890.0261487 ]\n",
      "State (19, 7);: [-1217.4425427  -1033.21094707 -1224.43026353  -770.8269506 ]\n",
      "State (19, 8);: [ -942.71863798  -950.49272437 -1077.50369494  -662.23415989]\n",
      "State (19, 9);: [-917.1097385  -764.91991654 -941.83574001 -568.5970134 ]\n",
      "State (19, 10);: [-673.73705229 -687.95028037 -843.31778517 -474.4919045 ]\n",
      "State (19, 11);: [-780.16655121 -618.46872896 -832.36249541 -421.31726157]\n",
      "State (19, 12);: [-651.50998769 -515.40279729 -694.23870169 -338.87493694]\n",
      "State (19, 13);: [-579.09104898 -440.12299812 -627.76133445 -276.0020538 ]\n",
      "State (19, 14);: [-367.66126449 -375.99670438 -491.79281078 -187.31772689]\n",
      "State (19, 15);: [-310.0349894  -239.78866467 -328.43059418 -112.37850499]\n",
      "State (19, 16);: [-242.01660734 -208.0143773  -296.41594175  -87.0955171 ]\n",
      "State (19, 17);: [-137.07946412 -145.48793497 -196.19501578  -15.07845542]\n",
      "State (19, 18);: [-132.8819795  -100.0999999  -200.95474564   10.        ]\n",
      "State (19, 19);: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# print(best_q_table.shape)\n",
    "# for i in range(best_q_table.shape[0]):\n",
    "#     for j in range(best_q_table.shape[1]):\n",
    "#         print(f\"State ({i}, {j});: {best_q_table[i, j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename and Submit this file as **SRNO(5digit)_Assignment3.ipynb**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
